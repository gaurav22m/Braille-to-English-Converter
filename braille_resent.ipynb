{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOm/VXixurWB4pSJDSwK06J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaurav22m/Braille-to-English-Converter/blob/main/braille_resent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oh8ZobUQ1eN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import sklearn\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz19qLW3RYuB",
        "outputId": "73693b2c-b457-4d6f-e3f5-827aa662d9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to load images from a folder\n",
        "def load_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_images(images):\n",
        "    # Resize images to a consistent size\n",
        "    target_size = (100, 100)\n",
        "    resized_images = resize_images(images, target_size)\n",
        "\n",
        "    # Convert images to grayscale\n",
        "    grayscale_images = convert_to_grayscale(resized_images)\n",
        "\n",
        "    # Normalize pixel values\n",
        "    normalized_images = normalize_images(grayscale_images)\n",
        "\n",
        "    # Augment dataset if necessary\n",
        "    augmented_images = augment_dataset(normalized_images)\n",
        "\n",
        "    return augmented_images\n",
        "\n",
        "# Function to resize images\n",
        "def resize_images(images, target_size):\n",
        "    resized_images = []\n",
        "    for image in images:\n",
        "        resized_image = cv2.resize(image, target_size)\n",
        "        resized_images.append(resized_image)\n",
        "    return resized_images\n",
        "\n",
        "# Function to convert images to grayscale\n",
        "def convert_to_grayscale(images):\n",
        "    grayscale_images = []\n",
        "    for image in images:\n",
        "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        grayscale_images.append(grayscale_image)\n",
        "    return grayscale_images\n",
        "\n",
        "# Function to normalize pixel values\n",
        "def normalize_images(images):\n",
        "    normalized_images = []\n",
        "    for image in images:\n",
        "        normalized_image = image / 255.0  # Normalize pixel values to range [0, 1]\n",
        "        normalized_images.append(normalized_image)\n",
        "    return normalized_images\n",
        "\n",
        "# Function to augment dataset\n",
        "def augment_dataset(images):\n",
        "    augmented_images = []\n",
        "    for image in images:\n",
        "        augmented_images.append(image)\n",
        "    return augmented_images\n",
        "\n",
        "# Path to the folder containing images\n",
        "folder_path = '/content/drive/MyDrive/Braille Dataset2'\n",
        "\n",
        "# Load images from each class folder\n",
        "images_per_class = {}\n",
        "for class_folder in os.listdir(folder_path):\n",
        "    class_path = os.path.join(folder_path, class_folder)\n",
        "    if os.path.isdir(class_path):\n",
        "        images = load_images_from_folder(class_path)\n",
        "        preprocessed_images = preprocess_images(images)\n",
        "        images_per_class[class_folder] = preprocessed_images\n",
        "\n",
        "# Now 'images_per_class' dictionary contains preprocessed images for each class\n",
        "\n",
        "# Function to save preprocessed images to disk\n",
        "def save_preprocessed_images(images, output_folder):\n",
        "    for idx, image in enumerate(images):\n",
        "        output_path = os.path.join(output_folder, f\"image_{idx}.png\")\n",
        "        cv2.imwrite(output_path, (image * 255).astype(np.uint8))\n",
        "\n",
        "# Path to the folder to save preprocessed images\n",
        "output_folder = '/content/drive/MyDrive/Braille Dataset preprocessed'\n",
        "\n",
        "# Save preprocessed images for each class\n",
        "for class_name, images in images_per_class.items():\n",
        "    class_output_folder = os.path.join(output_folder, class_name)\n",
        "    os.makedirs(class_output_folder, exist_ok=True)\n",
        "    save_preprocessed_images(images, class_output_folder)\n"
      ],
      "metadata": {
        "id": "GC6HTDyGRlQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to split dataset into train, validation, and test sets\n",
        "def split_dataset(images_per_class, test_size=0.2, validation_size=0.25, random_state=None):\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    validation_images = []\n",
        "    validation_labels = []\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "\n",
        "    for class_name, images in images_per_class.items():\n",
        "        # Split images for each class\n",
        "        X_train, X_test, y_train, y_test = train_test_split(images, [class_name]*len(images), test_size=test_size, random_state=random_state, stratify=[class_name]*len(images))\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size/(1-test_size), random_state=random_state, stratify=y_train)\n",
        "\n",
        "        # Add split images to respective sets\n",
        "        train_images.extend(X_train)\n",
        "        train_labels.extend(y_train)\n",
        "        validation_images.extend(X_val)\n",
        "        validation_labels.extend(y_val)\n",
        "        test_images.extend(X_test)\n",
        "        test_labels.extend(y_test)\n",
        "\n",
        "    return train_images, validation_images, test_images, train_labels, validation_labels, test_labels\n",
        "\n",
        "# Split dataset\n",
        "train_images, validation_images, test_images, train_labels, validation_labels, test_labels = split_dataset(images_per_class)\n",
        "\n",
        "# Print sizes of each set\n",
        "print(\"Train set size:\", len(train_images))\n",
        "print(\"Validation set size:\", len(validation_images))\n",
        "print(\"Test set size:\", len(test_images))"
      ],
      "metadata": {
        "id": "SyIVnRA2VKHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ResNet architecture\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1  # Set expansion attribute\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=26):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Change input channels to 1\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self.make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define hyperparameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize model with double precision parameters\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2]).double()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Convert class names to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "validation_labels_encoded = label_encoder.transform(validation_labels)\n",
        "\n",
        "# Convert data to PyTorch tensors and create DataLoader\n",
        "train_dataset = TensorDataset(torch.tensor(train_images), torch.tensor(train_labels_encoded))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "validation_dataset = TensorDataset(torch.tensor(validation_images), torch.tensor(validation_labels_encoded))\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.double()  # Convert inputs to double\n",
        "        outputs = model(inputs.unsqueeze(1))  # Add an extra dimension for the single channel\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs = inputs.double()  # Convert inputs to double\n",
        "            labels = torch.tensor(labels)  # Convert labels to tensor format\n",
        "            outputs = model(inputs.unsqueeze(1))  # Add an extra dimension for the single channel\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Print statistics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_val_loss = val_loss / len(validation_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}, Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "56opWRF5YdpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Lists to store true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Iterate through the validation set and make predictions\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "        inputs = inputs.double()  # Convert inputs to double\n",
        "        labels = torch.tensor(labels)  # Convert labels to tensor format\n",
        "        outputs = model(inputs.unsqueeze(1))  # Add an extra dimension for the single channel\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        true_labels.extend(labels.numpy())\n",
        "        predicted_labels.extend(predicted.numpy())\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "9bfABRndZWqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty lists to store precision values and epochs\n",
        "validation_precision = []\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "# Validation loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs = inputs.double()  # Convert inputs to double\n",
        "            labels = torch.tensor(labels)  # Convert labels to tensor format\n",
        "            outputs = model(inputs.unsqueeze(1))  # Add an extra dimension for the single channel\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate precision for this epoch\n",
        "        precision = correct / total\n",
        "        validation_precision.append(precision)\n",
        "\n",
        "# Plot validation precision\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, validation_precision, marker='o', color='blue')\n",
        "plt.title('Validation Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.xticks(epochs)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cvNqu-GhzOqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classes\n",
        "classes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'\n",
        "            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p',\n",
        "           'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "           'y', 'z']\n",
        "\n",
        "# Calculate precision, recall, and f1-score for each class\n",
        "precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=classes)\n",
        "\n",
        "# Plot precision, recall, and f1-score for each class\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(classes, precision_per_class, marker='o', label='Precision')\n",
        "plt.plot(classes, recall_per_class, marker='o', label='Recall')\n",
        "plt.plot(classes, f1_per_class, marker='o', label='F1-score')\n",
        "\n",
        "plt.title('Precision, Recall, and F1-score per class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n0WNJe1duLYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classes\n",
        "classes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'\n",
        "            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p',\n",
        "           'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "           'y', 'z']\n",
        "\n",
        "# Calculate precision for each class\n",
        "precision_per_class, _, _, _ = precision_recall_fscore_support(true_labels, predicted_labels, labels=classes)\n",
        "\n",
        "# Plot precision for each class\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(classes, precision_per_class, marker='o', label='Precision', color='blue')\n",
        "\n",
        "plt.title('Precision per class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Precision')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "orWKa5PY1q1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize empty lists to store precision and recall values for each epoch\n",
        "validation_precision = []\n",
        "validation_recall = []\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "# Validation loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    true_positives = 0\n",
        "    false_negatives = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs = inputs.double()  # Convert inputs to double\n",
        "            labels = torch.tensor(labels)  # Convert labels to tensor format\n",
        "            outputs = model(inputs.unsqueeze(1))  # Add an extra dimension for the single channel\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            true_positives += ((predicted == labels) & (labels == 1)).sum().item()\n",
        "            false_negatives += ((predicted != labels) & (labels == 1)).sum().item()\n",
        "\n",
        "        # Calculate precision and recall for this epoch\n",
        "        precision = true_positives / (true_positives + (total - true_positives - false_negatives))\n",
        "        recall = true_positives / (true_positives + false_negatives)\n",
        "        validation_precision.append(precision)\n",
        "        validation_recall.append(recall)\n",
        "\n",
        "# Plot validation precision\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, validation_precision, marker='o', color='blue')\n",
        "plt.title('Validation Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.xticks(epochs)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot validation recall\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, validation_recall, marker='o', color='green')\n",
        "plt.title('Validation Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.xticks(epochs)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sJRhF6MB1z3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using pretrained resnet model**"
      ],
      "metadata": {
        "id": "eMEdvx4d2Aae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split dataset into train, validation, and test sets\n",
        "def split_dataset(images_per_class, test_size=0.2, validation_size=0.25, random_state=None):\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    validation_images = []\n",
        "    validation_labels = []\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "\n",
        "    for class_name, images in images_per_class.items():\n",
        "        # Split images for each class\n",
        "        X_train, X_test, y_train, y_test = train_test_split(images, [class_name]*len(images), test_size=test_size, random_state=random_state, stratify=[class_name]*len(images))\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size/(1-test_size), random_state=random_state, stratify=y_train)\n",
        "\n",
        "        # Add split images to respective sets\n",
        "        train_images.extend(X_train)\n",
        "        train_labels.extend(y_train)\n",
        "        validation_images.extend(X_val)\n",
        "        validation_labels.extend(y_val)\n",
        "        test_images.extend(X_test)\n",
        "        test_labels.extend(y_test)\n",
        "\n",
        "    return train_images, validation_images, test_images, train_labels, validation_labels, test_labels\n",
        "\n",
        "# Split dataset\n",
        "train_images, validation_images, test_images, train_labels, validation_labels, test_labels = split_dataset(images_per_class)\n",
        "\n",
        "# Print sizes of each set\n",
        "print(\"Train set size:\", len(train_images))\n",
        "print(\"Validation set size:\", len(validation_images))\n",
        "print(\"Test set size:\", len(test_images))"
      ],
      "metadata": {
        "id": "OZ1zJL6A7g4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
        "    transforms.ToTensor(),           # Convert images to tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet mean and std\n",
        "])\n",
        "\n",
        "# paths to our dataset directory\n",
        "train_dir = 'path/to/train/dataset'\n",
        "validation_dir = 'path/to/validation/dataset'\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "validation_dataset = torchvision.datasets.ImageFolder(root=validation_dir, transform=transform)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
        "\n",
        "# Load pre-trained ResNet model\n",
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze the pre-trained parameters\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the last fully connected layer to match the number of classes in your dataset\n",
        "num_classes = 26  # Change this according to your dataset\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # Change this as needed\n",
        "for epoch in range(num_epochs):\n",
        "    resnet.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Validation\n",
        "    resnet.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = resnet(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Print statistics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_val_loss = val_loss / len(validation_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}, Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "QkefvlJj1ztB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x16naDLa6Uxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}